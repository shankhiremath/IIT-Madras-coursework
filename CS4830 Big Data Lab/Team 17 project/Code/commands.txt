Creating a DataProc Cluster:
gcloud dataproc clusters create "bdl-yelp" \
     --region "us-central1" \
     --metadata 'PIP_PACKAGES=google-cloud-storage spark-nlp==3.0.3' \
     --worker-machine-type n1-standard-2 \
     --master-machine-type n1-standard-4 \
     --master-boot-disk-size=500GB \
     --worker-boot-disk-size=500GB \
     --image-version=1.5-ubuntu18 \
     --optional-components=ANACONDA,JUPYTER \
     --enable-component-gateway \
     --initialization-actions gs://dataproc-initialization-actions/python/pip-install.sh

Submitting a job to the DataProc Cluster:
gcloud dataproc jobs submit pyspark --cluster bdl-yelp\
    --region "us-central1"\
    --properties=spark.jars.packages=com.johnsnowlabs.nlp:spark-nlp_2.12:3.0.3\
    --driver-log-levels root=FATAL \
    gs://shank_bdl/<modelname>_model.py

Submitting Subscriber code to on Kafka VM:
python3 subscriber.py

Setting up Kafka VM
1. Window1 $ bin/zookeeper-server-start.sh config/zookeeper.properties
2. Window2 $ bin/kafka-server-start.sh config/server.properties
3. Window3 $ bin/kafka-topics.sh --create --topic KafkaYelp --bootstrap-server localhost:9092
4. sudo yum install -y nano
5. sudo yum install epel-release
6. sudo pip3 install kafka
7. sudo pip3 install google-cloud-storage
8. sudo pip3 install gcsfs
9. sudo pip3 install pyspark
10. sudo pip3 install numpy
11. sudo pip3 install pandas